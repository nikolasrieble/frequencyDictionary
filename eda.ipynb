{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pymongo\n",
    "import seaborn as sns\n",
    "from nltk import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = 14, 6\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(\"german\")\n",
    "stop_words = set(stopwords.words(\"german\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "CURRENT_PATH = Path.cwd()\n",
    "LANGUAGE = 'de'\n",
    "MONGO_DB = os.environ['MONGO_DB']\n",
    "mydb = pymongo.MongoClient(MONGO_DB)\n",
    "newspaper = mydb['newspaper']\n",
    "collection = newspaper[LANGUAGE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    collection_df = pd.read_csv('collection.csv')\n",
    "    collection_df = collection_df.assign(words=collection_df['words'].apply(ast.literal_eval))\n",
    "    collection_df = collection_df.assign(length=collection_df['words'].apply(len))\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    filtered = list()\n",
    "    collection_df = list()\n",
    "    for entry in collection.find({\"text\": {\"$exists\": True}, \"published_at\": {\"$type\": \"date\"}}):\n",
    "        title = entry.get('title')\n",
    "        published = entry.get('published_at')\n",
    "        author = entry.get('authors')\n",
    "        url = entry.get('url')\n",
    "\n",
    "        # Create some variables\n",
    "        year = published.year\n",
    "        month = published.month\n",
    "        source = url.split('/')[2]\n",
    "\n",
    "        # Process text\n",
    "        text = entry.get('text')\n",
    "        words = word_tokenize(text)\n",
    "        words = [w.lower() for w in words if w.isalpha()]\n",
    "        cleaned_words = [w for w in words if w not in stop_words]\n",
    "        df = pd.Series(dict(\n",
    "            title=title,\n",
    "            author=author,\n",
    "            published_at=published.strftime('%Y-%m-%d'),\n",
    "            month=month,\n",
    "            year=year,\n",
    "            words=cleaned_words,\n",
    "            source=source,\n",
    "            url=url,\n",
    "        ))\n",
    "\n",
    "        filtered_words = set(words) - set(cleaned_words)\n",
    "        filtered.append(filtered_words)\n",
    "        collection_df.append(df)\n",
    "\n",
    "    collection_df = pd.concat(collection_df, axis=1).T\n",
    "    collection_df.to_csv('collection.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "today = pd.to_datetime('now')\n",
    "a_week_ago = (today - pd.Timedelta('7 days')).strftime('%Y-%m-%d')\n",
    "a_month_ago = (today - pd.Timedelta('30 days')).strftime('%Y-%m-%d')\n",
    "six_months_ago = (today - pd.Timedelta('180 days')).strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_freq = (FreqDist(i) for i in collection_df.query('published_at >= @a_month_ago and length > 0')['words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = FreqDist()\n",
    "for i in all_freq:\n",
    "    freq += i\n",
    "\n",
    "freq.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n_papers_per_months = collection_df.groupby(['year', 'month'])['title'].count().rename('n_papers')\n",
    "n_papers_per_months.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n_sources = collection_df['source'].value_counts()\n",
    "n_sources.plot.bar();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
